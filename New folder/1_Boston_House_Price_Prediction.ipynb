{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ew239AoI2hsV"
      },
      "outputs": [],
      "source": [
        "# If load_boston does not work then download the data and use this.\n",
        "# Data : https://github.com/afnan47/sem8/blob/master/DL/1_boston_housing.csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./1_boston_housing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FEDjg8rsyi0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.loc[:, df.columns != 'MEDV']\n",
        "y = df.loc[:, df.columns == 'MEDV']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WnXbfzke2hsW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "mms.fit(X_train)\n",
        "X_train = mms.transform(X_train)\n",
        "X_test = mms.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL8VMy_fs3fl",
        "outputId": "9298feff-091f-41c8-8cad-506f750abd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7m71ooKs5of",
        "outputId": "d5a4028d-be21-4e76-eea5-4f136475d371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 2s 23ms/step - loss: 572.8688 - mae: 22.0295 - val_loss: 584.3182 - val_mae: 22.1855\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 517.7371 - mae: 20.6949 - val_loss: 514.6352 - val_mae: 20.4990\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 435.5746 - mae: 18.4558 - val_loss: 409.1986 - val_mae: 17.6105\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 321.1058 - mae: 15.0272 - val_loss: 275.9344 - val_mae: 13.3944\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 203.7632 - mae: 11.2772 - val_loss: 165.1430 - val_mae: 9.0303\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 142.3871 - mae: 9.2507 - val_loss: 126.7690 - val_mae: 8.0826\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 126.2097 - mae: 8.6382 - val_loss: 113.9197 - val_mae: 7.6391\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 108.1819 - mae: 7.8286 - val_loss: 107.1465 - val_mae: 7.2135\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 92.1332 - mae: 7.0612 - val_loss: 96.9038 - val_mae: 6.7807\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 81.3920 - mae: 6.5981 - val_loss: 87.7108 - val_mae: 6.4446\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71.2290 - mae: 6.1117 - val_loss: 83.0688 - val_mae: 6.1110\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 64.4996 - mae: 5.7696 - val_loss: 77.2769 - val_mae: 6.0327\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.7629 - mae: 5.4686 - val_loss: 74.0755 - val_mae: 5.9097\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 54.5584 - mae: 5.1836 - val_loss: 71.4519 - val_mae: 5.8291\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 51.5373 - mae: 5.0014 - val_loss: 68.8070 - val_mae: 5.8020\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 48.9251 - mae: 4.8918 - val_loss: 66.5856 - val_mae: 5.7531\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47.0678 - mae: 4.7189 - val_loss: 65.1385 - val_mae: 5.5808\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.5693 - mae: 4.6932 - val_loss: 61.4257 - val_mae: 5.8927\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.9802 - mae: 4.6559 - val_loss: 60.9249 - val_mae: 5.4516\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.7580 - mae: 4.3372 - val_loss: 59.9764 - val_mae: 5.2682\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.6457 - mae: 4.2326 - val_loss: 56.6951 - val_mae: 5.3119\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36.9803 - mae: 4.2755 - val_loss: 53.6874 - val_mae: 5.3320\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.9744 - mae: 4.0975 - val_loss: 53.2854 - val_mae: 5.0902\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.3712 - mae: 3.9603 - val_loss: 51.6478 - val_mae: 4.9857\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.8136 - mae: 3.9577 - val_loss: 48.7278 - val_mae: 5.0019\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 30.0418 - mae: 3.7580 - val_loss: 48.4767 - val_mae: 4.7767\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.6136 - mae: 3.6681 - val_loss: 45.7398 - val_mae: 4.7741\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.3128 - mae: 3.6235 - val_loss: 45.0190 - val_mae: 4.7098\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.8708 - mae: 3.4773 - val_loss: 43.3428 - val_mae: 4.6719\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.9759 - mae: 3.4778 - val_loss: 41.5568 - val_mae: 4.6333\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.6850 - mae: 3.3367 - val_loss: 42.2573 - val_mae: 4.5538\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 23.1328 - mae: 3.2134 - val_loss: 40.5184 - val_mae: 4.5178\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 22.0203 - mae: 3.2443 - val_loss: 38.7687 - val_mae: 4.5021\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.3376 - mae: 3.1629 - val_loss: 39.7164 - val_mae: 4.4229\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.7162 - mae: 3.0880 - val_loss: 38.0668 - val_mae: 4.3890\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 20.2456 - mae: 3.0525 - val_loss: 37.2446 - val_mae: 4.3481\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.8578 - mae: 3.0607 - val_loss: 37.4612 - val_mae: 4.2771\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.3708 - mae: 2.9928 - val_loss: 36.3970 - val_mae: 4.2366\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.9733 - mae: 3.0099 - val_loss: 34.7837 - val_mae: 4.1864\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.4733 - mae: 2.9402 - val_loss: 36.8849 - val_mae: 4.1466\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.4539 - mae: 2.8963 - val_loss: 34.3881 - val_mae: 4.0750\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.6323 - mae: 3.0138 - val_loss: 34.0892 - val_mae: 4.0315\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.0655 - mae: 2.8531 - val_loss: 35.2554 - val_mae: 4.0082\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 17.6432 - mae: 2.8544 - val_loss: 33.0276 - val_mae: 3.9444\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 17.4875 - mae: 2.8268 - val_loss: 33.2157 - val_mae: 3.9090\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.1498 - mae: 2.8010 - val_loss: 31.9545 - val_mae: 3.8330\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.0073 - mae: 2.8151 - val_loss: 32.9263 - val_mae: 3.8049\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.8884 - mae: 2.7564 - val_loss: 31.8682 - val_mae: 3.7445\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.6385 - mae: 2.7648 - val_loss: 31.3929 - val_mae: 3.6995\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.5297 - mae: 2.7265 - val_loss: 31.8695 - val_mae: 3.6897\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3818 - mae: 2.7453 - val_loss: 30.5203 - val_mae: 3.6313\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.3157 - mae: 2.6989 - val_loss: 30.7371 - val_mae: 3.6314\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.1480 - mae: 2.7340 - val_loss: 30.2993 - val_mae: 3.5848\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 16.0188 - mae: 2.6705 - val_loss: 30.6204 - val_mae: 3.5792\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8530 - mae: 2.6651 - val_loss: 29.1451 - val_mae: 3.4952\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.8102 - mae: 2.6992 - val_loss: 30.7497 - val_mae: 3.5412\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.6498 - mae: 2.6632 - val_loss: 28.7871 - val_mae: 3.4451\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.4277 - mae: 2.6457 - val_loss: 30.6821 - val_mae: 3.5204\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.6039 - mae: 2.6261 - val_loss: 28.6913 - val_mae: 3.4119\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.5488 - mae: 2.7222 - val_loss: 27.9299 - val_mae: 3.3812\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.2724 - mae: 2.6113 - val_loss: 29.7626 - val_mae: 3.4252\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0895 - mae: 2.6171 - val_loss: 27.9391 - val_mae: 3.3313\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.0499 - mae: 2.6322 - val_loss: 28.8469 - val_mae: 3.3604\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0201 - mae: 2.5777 - val_loss: 27.1854 - val_mae: 3.3057\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.2640 - mae: 2.6969 - val_loss: 29.5099 - val_mae: 3.3510\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.8765 - mae: 2.5585 - val_loss: 27.1458 - val_mae: 3.2539\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7411 - mae: 2.5773 - val_loss: 27.5534 - val_mae: 3.2444\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6798 - mae: 2.5854 - val_loss: 27.7867 - val_mae: 3.2461\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4993 - mae: 2.5441 - val_loss: 26.6033 - val_mae: 3.1911\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4307 - mae: 2.5489 - val_loss: 26.5953 - val_mae: 3.1921\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.3467 - mae: 2.5516 - val_loss: 26.9334 - val_mae: 3.1920\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4285 - mae: 2.5620 - val_loss: 27.3309 - val_mae: 3.2032\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4815 - mae: 2.5147 - val_loss: 25.8911 - val_mae: 3.1756\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2235 - mae: 2.5410 - val_loss: 26.1964 - val_mae: 3.1522\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.0572 - mae: 2.5220 - val_loss: 26.1352 - val_mae: 3.1491\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.0086 - mae: 2.5338 - val_loss: 25.8199 - val_mae: 3.1190\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.9972 - mae: 2.5243 - val_loss: 25.4110 - val_mae: 3.0758\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1458 - mae: 2.5224 - val_loss: 25.2187 - val_mae: 3.0911\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.7629 - mae: 2.4993 - val_loss: 25.3191 - val_mae: 3.0688\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8043 - mae: 2.4877 - val_loss: 25.0069 - val_mae: 3.0798\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6069 - mae: 2.4784 - val_loss: 25.6617 - val_mae: 3.0598\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6046 - mae: 2.4718 - val_loss: 24.9129 - val_mae: 3.0522\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7579 - mae: 2.5444 - val_loss: 25.7212 - val_mae: 3.0459\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.5627 - mae: 2.4597 - val_loss: 24.9831 - val_mae: 2.9960\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4181 - mae: 2.4849 - val_loss: 24.0465 - val_mae: 3.0007\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3524 - mae: 2.4420 - val_loss: 25.0666 - val_mae: 2.9908\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3981 - mae: 2.4667 - val_loss: 24.6416 - val_mae: 2.9748\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6013 - mae: 2.4595 - val_loss: 23.0061 - val_mae: 2.9825\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3672 - mae: 2.4933 - val_loss: 24.9650 - val_mae: 2.9782\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0207 - mae: 2.4370 - val_loss: 23.0349 - val_mae: 2.9170\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1179 - mae: 2.4597 - val_loss: 23.9199 - val_mae: 2.9232\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.9656 - mae: 2.4248 - val_loss: 22.8505 - val_mae: 2.8999\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.9792 - mae: 2.4402 - val_loss: 23.3187 - val_mae: 2.8695\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.9575 - mae: 2.4462 - val_loss: 22.9472 - val_mae: 2.8714\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7855 - mae: 2.3981 - val_loss: 22.8469 - val_mae: 2.8410\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9748 - mae: 2.4679 - val_loss: 24.0257 - val_mae: 2.8950\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1027 - mae: 2.4241 - val_loss: 21.4380 - val_mae: 2.8532\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7012 - mae: 2.4179 - val_loss: 22.4944 - val_mae: 2.8114\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5984 - mae: 2.3756 - val_loss: 22.3271 - val_mae: 2.7753\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7070 - mae: 2.3746 - val_loss: 21.7075 - val_mae: 2.7967\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzY8zjL5s9jS",
        "outputId": "d2d17131-2742-4d5b-8a33-56b176e299c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 22.1527 - mae: 3.0131\n",
            "Mean squared error on test data:  22.152725219726562\n",
            "Mean absolute error on test data:  3.0131425857543945\n"
          ]
        }
      ],
      "source": [
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error on test data: ', mse_nn)\n",
        "print('Mean absolute error on test data: ', mae_nn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}